{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-docx in c:\\users\\rupal\\anaconda3\\lib\\site-packages (0.8.10)\n",
      "Requirement already satisfied: lxml>=2.3.2 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from python-docx) (4.5.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx as wo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = wo.Document('Deepika Padukone-Data Analyst or Engineer.docx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'National University of Singapore M-Tech in Enterprise Business Analytics [Jan 2017 â€“ May 2018]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume.paragraphs[12].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\rupal\\anaconda3\\lib\\site-packages (3.5)\n",
      "Requirement already satisfied: click in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from nltk) (0.16.0)\n",
      "Requirement already satisfied: regex in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from nltk) (2020.6.8)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from nltk) (4.47.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import string\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullText = []\n",
    "for paragraph in resume.paragraphs:\n",
    "     fullText.append(paragraph.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fulltext(text): \n",
    "    tokens=' '.join(text)    \n",
    "    return(tokens)\n",
    "\n",
    "resume1 = fulltext(fullText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume1=pd.Series(resume1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume1=resume1.replace('[^A-Za-z0-9]+',' ',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "newstopwords=stopwords.words(\"English\") + ['play','will','within','one','use','make','way','across','need','care','help','high','must','area','state','people','member','may','well','using','etc','make','year','office',\n",
    "                                           'us','change','part','access','time','able','issue','task','duties','day','field','meet','hand','first','ensure','best','sexual','gender','global','world','race','regard','client',\n",
    "                                           'http','re','ad','self','highly','key','source','make','come','full','result','inc','build','end','color','years','work','role','family','date','team','equal','com',\n",
    "                                           'u','law','www','com','please','life','also','level','new','non','system','service','sex','age','email','job','pay','duty','take','ha','a','b','d','e','f','g','strong',\n",
    "                                          'status','offer','good','term','matter','open','get','person','ideal','place','title','go','inc','see','hour','tx','ca','skill','strong','month','pay',\n",
    "                                          'degree','design','tool','build','client','drive','large','create','plan','user','lead','value','apply','review','learn','fast','assist','detail','manage','impact','type',\n",
    "                                           'make','origin','make','policy','need','join','goal','expert','group','hire','need','method','action','focus','basis','cross','make','based','degree','skill','year','origin','austin',\n",
    "                                           'need','pace','basic','right','wide','others','multi','pay','want','use','long','give','small','hire','bachelor','report','-','+','\"']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "WNlemma = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(text): \n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens=[t.lower() for t in tokens]\n",
    "    tokens=[t for t in tokens if t not in string.punctuation]\n",
    "    tokens=[ t for t in tokens if (not t.isnumeric())]\n",
    "    tokens=[WNlemma.lemmatize(t) for t in tokens]\n",
    "    tokens=[word for word in tokens if word not in newstopwords]\n",
    "    tokens=' '.join(tokens)\n",
    "    return(tokens)\n",
    "\n",
    "resume2=resume1.apply(pre_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume2=resume2.replace(['pl sql','masters','git github','github','microsoft word','ms word','powerpoint','power point','data governance','statistics','mathematics','computer science','data analyst','big data','modelling','microsoft office','ms office','java script','javascript','deep learning','tableau','engineering','datasets','data sets','dataset','data set','dashboards','dashboard','databases','data base',' sa ','regression','clustering','artificial intelligence',' ms ','mongodb','tensorflow','rapidminer','rainstor','elasticsearch','elastic search','airflow','kubernetes','tensor flow','air flow','power bi','scrum master','sisense','data studio','grafana','mapreduce','couchbase','blockchain','spotfire','chartio','metabase','cassandra','periscope data','dynamodb','firebase','big query',' teradata ','ad hoc','machine learning',' natural language processing ','decision tree','neural network','graduate','undergraduate','bachelor','analtyical','analytics','analysis','classification','business analyst','business intelligence'],['PLSQL','master','GIT','GIT','msword','msword','PPT','PPT','DAG','stats','math','cse','anali','bdata','model','mso','mso','jas','jas','deepl','tabl','engg','dset','dset','dset','dset','dashb','dashb','db','db',' sas ','resn','cstg','ai','master','mgd','tefw','rpdm','rst','elsch','elsch','afw','kbnts','tefw','afw','bi','scr','sss','dtd','gfn','mrc','ccb','bcn','spfr','chto','mtbse','ssdr','prsc','dymd','fibs','bqry',' tdata ','adhoc','maclrg',' nlp ','dctre','nurnet','grad','undergrad','bach','ana','anacs','anasis','clas','busst','busnc'],regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def length(text):\n",
    "    tokens=nltk.word_tokenize(text)\n",
    "    tokens=[t for t in tokens if len(t)<7]\n",
    "    tokens=set(tokens)\n",
    "    tokens=' '.join(tokens)\n",
    "    return(tokens)\n",
    "\n",
    "resume3=resume2.apply(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume3=resume3.replace(['DAG',' stats ',' math ',' cse ',' anali ',' bdata ',' model ',' mso ',' jas ',' deepl ',' tabl ',' engg ',' dset ',' dashb ',' db ',' teg ',' resn ',' cstg ',' mgd ',' tefw ',' rpdm ',' rst ',' elsch ',' afw ',' ai ',' kbnts ',' bi ',' scr ',' sss ',' dtd ',' gfn ',' mrc ',' ccb ',' bcn ',' spfr ',' chto ',' mtbse ',' ssdr ','data',' prsc ',' dymd ',' fibs ',' big ',' set ',' bqry ',' tdata ','adhoc','maclrg',' nlp ','dctre','nurnet',' grad ',' undergrad ',' bach ',' ana ',' anacs ',' anasis ',' clas ',' busst ',' busnc '],['datagovernance',' statistics ',' mathematics ',' computerscience ',' analyst ',' bigdata ',' modelling ',' msoffice ',' javascript ',' deeplearning ',' tableau ',' engineering ',' dataset ',' dashborads ',' databases ',' text mining ',' regression ',' clustering ',' mongodb ',' tensorflow ',' rapidminer ',' rainstor ',' elasticsearch ',' airflow ',' artificialintelligence ',' kubernetes ',' powerbi ',' scrum',' sisense ',' datastudio ',' grafana ',' mapreduce ',' couchbase ',' blockchain ',' spotfire ',' chartio ',' metabase ',' cassandra ','',' periscopedata',' dynamodb ',' firebase ','','',' bigquery ',' teradata ','adhoc','machine learning','natural launguage processing','decision tree','neural network',' graduate ',' undergraduate ',' bachelor ',' analytical ',' analytics ',' analysis ',' classification ',' businessanalyst',' businessintelligence '],regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill=['web','linux','java','c','r','python','sql','plsql','oracle','excel','sap','sas','cloud','plsql','postgresql','bigdata','hedis','hadoop','spark','teradata','pig','hive','deeplearning','kafta','hbase','splunk','presto','rapidminer','knime','hunk','beam','tensorflow','mongodb','aws','machinelaerning','mysql','etl','rainstor','airflow','kubernetes','docker','plotly','knime','splunk','elasticsearch','rainstor','ppt','msword',' r ','looker','powerbi','tableau','azure','nosql','git','javascript','artificialintelligence','scrum','spss','cassandra','orange','mapreduce','couchbase','ems','blockchain','orange','spotfire','chartio','cognos','metabase','sisense','qlik','redash','grafana','datastudio','orange','mode','periscopedata','pmp','api','dynamodb','oltp','olap','firebase','redis','sap','msoffice','bigquery','teradata','machine learning','decision tree','neural network','database','adhoc','dashboard','mining','deeplearning','nlp','modelling','regression','clustering','dataanalsyt','mathematics','engineering','statistics','phd','master','businessintelligence','classification','analysis','analytical','analytics','bachelor','graduate','undergraduate','businessanalyst','master','phd','mathematics','statistics','engineering','computerscience']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skills(text):\n",
    "    tokens=nltk.word_tokenize(text)\n",
    "    tokens=[t for t in tokens if(t in skill)]\n",
    "    tokens=' '.join(tokens)\n",
    "    return(tokens)\n",
    "\n",
    "resume3=resume3.apply(skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'clustering spark excel regression hadoop engineering java spss mining web sql modelling analytics analysis c python r qlik'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'clustering spark excel regression hadoop engineering java spss mining web sql modelling analytics analysis c python r qlik'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume4=str(resume3[0])\n",
    "resume4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumefile=open('resume.txt',mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumefile.write(resume4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
